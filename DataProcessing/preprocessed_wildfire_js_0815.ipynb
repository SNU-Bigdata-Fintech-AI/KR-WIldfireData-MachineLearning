{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0d6c1a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "행: 3560, 열: 47\n",
      "\n",
      "컬럼명:\n",
      "['WRINV_NO', 'FIRE_TYPE_NM', 'SMTPR_LCLSF_NM', 'SMTPR_SCLSF_NM', 'DTH_CNT', 'INJPSN_CNT', 'HNL_DAM_CNT', 'PRPT_DAM_AMT', 'DOW_NM', 'FRSTN_NM', 'CNTR_NM', 'RCPT_DT', 'DSPT_DT', 'GRNDS_ARVL_DT', 'BGNN_POTFR_DT', 'PRFECT_POTFR_DT', 'CBK_DT', 'DSPT_REQ_HR', 'FIRE_SUPESN_HR', 'CTPV_NM', 'SGG_NM', 'FRSTN_GRNDS_DSTNC', 'CNTR_GRNDS_DSTNC', 'LFDAU_GRNDS_DSTNC', 'IGTN_HTSRC_NM', 'IGTN_HTSRC_SCLSF_NM', 'IGTN_DMNT_LCLSF_NM', 'IGTN_DMNT_SCLSF_NM', 'FRST_IGOBJ_LCLSF_NM', 'FRST_IGOBJ_SCLSF_NM', 'IGTN_ISTR_LCLSF_NM', 'IGTN_ISTR_SCLSF_NM', 'CMBS_EXPOBJ_LCLSF_NM', 'CMBS_EXPOBJ_SCLSF_NM', 'FCLT_PLC_LCLSF_NM', 'FCLT_PLC_MCLSF_NM', 'FCLT_PLC_SCLSF_NM', 'SO_AREA', 'FIRE_INSRNC_OBLG_TRGT_YN', 'ARSON_MNG_TRGT_YN', 'MUB_YN', 'FND_FIRE_SE_NM', 'FND_IGTN_PSTN_NM', 'HR_UNIT_ARTMP', 'HR_UNIT_WSPD_INFO', 'WNDRCT_BRNG', 'HR_UNIT_HUM']\n",
      "\n",
      "처음 5행:\n",
      "          WRINV_NO FIRE_TYPE_NM SMTPR_LCLSF_NM SMTPR_SCLSF_NM  DTH_CNT  \\\n",
      "0  190120062707724           임야            NaN            NaN        0   \n",
      "1  190311055543741           임야            NaN            NaN        0   \n",
      "2  190306044659961           임야            NaN            NaN        0   \n",
      "3  190331133539629           임야            NaN            NaN        0   \n",
      "4  191231033646630           임야            NaN            NaN        0   \n",
      "\n",
      "   INJPSN_CNT  HNL_DAM_CNT  PRPT_DAM_AMT DOW_NM FRSTN_NM  ... SO_AREA  \\\n",
      "0           0            0             0      일    동작소방서  ...     NaN   \n",
      "1           0            0             0      월    동작소방서  ...     NaN   \n",
      "2           0            0           275      수    동작소방서  ...     NaN   \n",
      "3           0            0             1      일    동부소방서  ...     NaN   \n",
      "4           0            0          1100      화    고성소방서  ...     NaN   \n",
      "\n",
      "   FIRE_INSRNC_OBLG_TRGT_YN  ARSON_MNG_TRGT_YN  MUB_YN  FND_FIRE_SE_NM  \\\n",
      "0                         N                  N       N             국유림   \n",
      "1                         N                  N       N             공유림   \n",
      "2                         N                  N       N             국유림   \n",
      "3                         N                  N       N             국유림   \n",
      "4                         N                  N       N             사유림   \n",
      "\n",
      "   FND_IGTN_PSTN_NM  HR_UNIT_ARTMP  HR_UNIT_WSPD_INFO  WNDRCT_BRNG HR_UNIT_HUM  \n",
      "0               산아래           -1.0            0~4 m/s           북서        39.0  \n",
      "1               산아래            5.0            0~4 m/s           남서        60.0  \n",
      "2               산아래            7.0            0~4 m/s           남서        49.0  \n",
      "3               산중턱            0.3           9~12 m/s           북서        48.0  \n",
      "4                평지           -8.7          18 m/s 이상            서        36.0  \n",
      "\n",
      "[5 rows x 47 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 파일 읽기\n",
    "df = pd.read_csv(\"wildfire_2019_2023_combine.csv\")\n",
    "\n",
    "# 기본 정보 확인\n",
    "print(f\"행: {len(df)}, 열: {len(df.columns)}\")\n",
    "print(\"\\n컬럼명:\")\n",
    "print(df.columns.tolist())\n",
    "print(\"\\n처음 5행:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2756a12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "제거할 컬럼 개수: 30\n",
      "제거할 컬럼들: ['HNL_DAM_CNT', 'SMTPR_LCLSF_NM', 'PRFECT_POTFR_DT', 'CNTR_NM', 'SO_AREA', 'FIRE_TYPE_NM', 'PRPT_DAM_AMT', 'IGTN_HTSRC_SCLSF_NM', 'CMBS_EXPOBJ_SCLSF_NM', 'DTH_CNT', 'IGTN_ISTR_LCLSF_NM', 'IGTN_ISTR_SCLSF_NM', 'MUB_YN', 'IGTN_HTSRC_NM', 'WRINV_NO', 'INJPSN_CNT', 'SMTPR_SCLSF_NM', 'IGTN_DMNT_SCLSF_NM', 'FIRE_INSRNC_OBLG_TRGT_YN', 'CMBS_EXPOBJ_LCLSF_NM', 'ARSON_MNG_TRGT_YN', 'FCLT_PLC_MCLSF_NM', 'BGNN_POTFR_DT', 'DOW_NM', 'FRST_IGOBJ_LCLSF_NM', 'CBK_DT', 'FRST_IGOBJ_SCLSF_NM', 'IGTN_DMNT_LCLSF_NM', 'FRSTN_NM', 'FCLT_PLC_LCLSF_NM']\n",
      "\n",
      "원본 데이터: 행 3560, 열 47\n",
      "컬럼 제거된 데이터: 행 3560, 열 17\n",
      "\n",
      "남은 컬럼들:\n",
      "['RCPT_DT', 'DSPT_DT', 'GRNDS_ARVL_DT', 'DSPT_REQ_HR', 'FIRE_SUPESN_HR', 'CTPV_NM', 'SGG_NM', 'FRSTN_GRNDS_DSTNC', 'CNTR_GRNDS_DSTNC', 'LFDAU_GRNDS_DSTNC', 'FCLT_PLC_SCLSF_NM', 'FND_FIRE_SE_NM', 'FND_IGTN_PSTN_NM', 'HR_UNIT_ARTMP', 'HR_UNIT_WSPD_INFO', 'WNDRCT_BRNG', 'HR_UNIT_HUM']\n"
     ]
    }
   ],
   "source": [
    "# 제거할 컬럼 목록 (대소문자 구분 없이 처리)\n",
    "columns_to_remove = [\n",
    "    'bldg_rscu_dngct', 'bldg_srtfrm_nm', 'bldg_strctr_nm', 'bldg_srtrf_nm', \n",
    "    'bldg_stts_nm', 'bldg_gfa', 'so_area', 'mub_yn', 'smtpr_lclsf_nm', \n",
    "    'smtpr_sclsf_nm', 'bttm_area', 'igtn_istr_lclsf_nm', 'igtn_istr_sclsf_nm',\n",
    "    'igtn_htsrc_nm', 'igtn_htsrc_sclsf_nm', 'igtn_dmnt_lclsf_nm', 'igtn_dmnt_sclsf_nm',\n",
    "    'igtn_flr_nm', 'arson_mng_trgt_yn', 'cbk_dt', 'injpsn_cnt', 'dth_cnt',\n",
    "    'cntr_nm', 'frstn_nm', 'fclt_plc_lclsf_nm', 'fclt_plc_mclsf_nm', \n",
    "    'cmbs_expobj_lclsf_nm', 'cmbs_expobj_sclsf_nm', 'prfect_potfr_dt', 'dow_nm',\n",
    "    'hnl_dam_cnt', 'prpt_dam_amt', 'wrinv_no', 'grnd_nofl', 'udgd_nofl',\n",
    "    'vhcl_igtn_pstn_nm', 'vhcl_plc_nm', 'bgnn_potfr_dt', 'frst_igobj_lclsf_nm',\n",
    "    'frst_igobj_sclsf_nm', 'spfptg_nm', 'fire_insrnc_oblg_trgt_yn', 'fire_type_nm'\n",
    "]\n",
    "\n",
    "# 원본 df를 복사하여 컬럼 제거용 데이터프레임 생성\n",
    "df_col_removed = df.copy()\n",
    "\n",
    "# 현재 데이터프레임에 존재하는 컬럼만 필터링 (대소문자 구분 없이)\n",
    "existing_columns_to_remove = []\n",
    "for col_to_remove in columns_to_remove:\n",
    "    # 대소문자 구분 없이 매칭되는 컬럼 찾기\n",
    "    matching_cols = [col for col in df_col_removed.columns if col.lower() == col_to_remove.lower()]\n",
    "    existing_columns_to_remove.extend(matching_cols)\n",
    "\n",
    "# 중복 제거\n",
    "existing_columns_to_remove = list(set(existing_columns_to_remove))\n",
    "\n",
    "print(f\"제거할 컬럼 개수: {len(existing_columns_to_remove)}\")\n",
    "print(f\"제거할 컬럼들: {existing_columns_to_remove}\")\n",
    "\n",
    "# 컬럼 제거\n",
    "df_col_removed = df_col_removed.drop(columns=existing_columns_to_remove, errors='ignore')\n",
    "\n",
    "print(f\"\\n원본 데이터: 행 {len(df)}, 열 {len(df.columns)}\")\n",
    "print(f\"컬럼 제거된 데이터: 행 {len(df_col_removed)}, 열 {len(df_col_removed.columns)}\")\n",
    "print(f\"\\n남은 컬럼들:\")\n",
    "print(df_col_removed.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "95285bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 결측치 현황 ===\n",
      "결측치가 있는 컬럼 수: 2\n",
      "\n",
      "결측치 상세:\n",
      "              컬럼명  결측치 개수  결측치 비율(%)\n",
      "           SGG_NM      36   1.011236\n",
      "LFDAU_GRNDS_DSTNC      10   0.280899\n",
      "\n",
      "전체 데이터 행 수: 3560\n",
      "전체 컬럼 수: 17\n"
     ]
    }
   ],
   "source": [
    "# 결측치 확인\n",
    "print(\"=== 결측치 현황 ===\")\n",
    "missing_info = df_col_removed.isnull().sum()\n",
    "missing_percent = (df_col_removed.isnull().sum() / len(df_col_removed)) * 100\n",
    "\n",
    "# 결측치가 있는 컬럼만 표시\n",
    "missing_df = pd.DataFrame({\n",
    "    '컬럼명': missing_info.index,\n",
    "    '결측치 개수': missing_info.values,\n",
    "    '결측치 비율(%)': missing_percent.values\n",
    "})\n",
    "\n",
    "# 결측치가 0개가 아닌 컬럼만 필터링\n",
    "missing_df = missing_df[missing_df['결측치 개수'] > 0]\n",
    "\n",
    "if len(missing_df) > 0:\n",
    "    print(f\"결측치가 있는 컬럼 수: {len(missing_df)}\")\n",
    "    print(\"\\n결측치 상세:\")\n",
    "    print(missing_df.sort_values('결측치 개수', ascending=False).to_string(index=False))\n",
    "else:\n",
    "    print(\"결측치가 없습니다!\")\n",
    "\n",
    "print(f\"\\n전체 데이터 행 수: {len(df_col_removed)}\")\n",
    "print(f\"전체 컬럼 수: {len(df_col_removed.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "131e2e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== LFDAU_GRNDS_DSTNC 컬럼 전처리 (Missing Labeling) ===\n",
      "전처리 전:\n",
      "- 총 데이터 수: 3560\n",
      "- 결측치 수: 10\n",
      "- 0값 개수: 2436\n",
      "\n",
      "전처리 후:\n",
      "- 총 데이터 수: 3560\n",
      "- 결측치 수: 0\n",
      "- -1값 개수 (missing label): 2446\n",
      "- 0값 개수: 0\n",
      "\n",
      "LFDAU_GRNDS_DSTNC 컬럼 값 분포:\n",
      "LFDAU_GRNDS_DSTNC\n",
      "-1.0     2446\n",
      " 1.0       59\n",
      " 2.0      102\n",
      " 3.0      117\n",
      " 4.0      126\n",
      " 5.0      133\n",
      " 6.0      119\n",
      " 7.0       76\n",
      " 8.0       75\n",
      " 9.0       56\n",
      " 10.0      40\n",
      " 11.0      54\n",
      " 12.0      38\n",
      " 13.0      22\n",
      " 14.0      15\n",
      " 15.0      18\n",
      " 16.0      15\n",
      " 17.0       9\n",
      " 18.0       7\n",
      " 19.0       9\n",
      " 20.0       3\n",
      " 21.0       3\n",
      " 22.0       2\n",
      " 23.0       3\n",
      " 24.0       1\n",
      " 25.0       2\n",
      " 26.0       1\n",
      " 27.0       1\n",
      " 28.0       1\n",
      " 29.0       3\n",
      " 33.0       2\n",
      " 34.0       1\n",
      " 38.0       1\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2q/_8m2fvxd4pv04q2b3gk8j0bm0000gn/T/ipykernel_48554/134255478.py:16: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_lfdau_processed['LFDAU_GRNDS_DSTNC'] = df_lfdau_processed['LFDAU_GRNDS_DSTNC'].fillna(-1)\n"
     ]
    }
   ],
   "source": [
    "# LFDAU_GRNDS_DSTNC 컬럼 전처리용 데이터프레임 생성\n",
    "df_lfdau_processed = df_col_removed.copy()\n",
    "\n",
    "print(\"=== LFDAU_GRNDS_DSTNC 컬럼 전처리 (Missing Labeling) ===\")\n",
    "\n",
    "# 전처리 전 상태 확인\n",
    "print(\"전처리 전:\")\n",
    "print(f\"- 총 데이터 수: {len(df_lfdau_processed)}\")\n",
    "print(f\"- 결측치 수: {df_lfdau_processed['LFDAU_GRNDS_DSTNC'].isnull().sum()}\")\n",
    "print(f\"- 0값 개수: {(df_lfdau_processed['LFDAU_GRNDS_DSTNC'] == 0).sum()}\")\n",
    "\n",
    "# 1단계: 0 값을 결측치로 변환\n",
    "df_lfdau_processed['LFDAU_GRNDS_DSTNC'] = df_lfdau_processed['LFDAU_GRNDS_DSTNC'].replace(0, pd.NA)\n",
    "\n",
    "# 2단계: 모든 결측치를 -1로 채우기 (missing labeling)\n",
    "df_lfdau_processed['LFDAU_GRNDS_DSTNC'] = df_lfdau_processed['LFDAU_GRNDS_DSTNC'].fillna(-1)\n",
    "\n",
    "# 전처리 후 상태 확인\n",
    "print(\"\\n전처리 후:\")\n",
    "print(f\"- 총 데이터 수: {len(df_lfdau_processed)}\")\n",
    "print(f\"- 결측치 수: {df_lfdau_processed['LFDAU_GRNDS_DSTNC'].isnull().sum()}\")\n",
    "print(f\"- -1값 개수 (missing label): {(df_lfdau_processed['LFDAU_GRNDS_DSTNC'] == -1).sum()}\")\n",
    "print(f\"- 0값 개수: {(df_lfdau_processed['LFDAU_GRNDS_DSTNC'] == 0).sum()}\")\n",
    "\n",
    "# LFDAU_GRNDS_DSTNC 컬럼의 값 분포 확인\n",
    "print(f\"\\nLFDAU_GRNDS_DSTNC 컬럼 값 분포:\")\n",
    "print(df_lfdau_processed['LFDAU_GRNDS_DSTNC'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7976b455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 레이블 인코딩 진행 ===\n",
      "\n",
      "[SGG_NM] 레이블 인코딩 중...\n",
      "매칭 테이블: {'nan': np.int64(0), '가평군': np.int64(1), '강남구': np.int64(2), '강동구': np.int64(3), '강릉시': np.int64(4), '강북구': np.int64(5), '강서구': np.int64(6), '강진군': np.int64(7), '강화군': np.int64(8), '거제시': np.int64(9), '거창군': np.int64(10), '경산시': np.int64(11), '경주시': np.int64(12), '계룡시': np.int64(13), '계양구': np.int64(14), '고령군': np.int64(15), '고성군': np.int64(16), '고양시 덕양구': np.int64(17), '고양시 일산동구': np.int64(18), '고양시 일산서구': np.int64(19), '고창군': np.int64(20), '고흥군': np.int64(21), '곡성군': np.int64(22), '공주시': np.int64(23), '과천시': np.int64(24), '관악구': np.int64(25), '광명시': np.int64(26), '광산구': np.int64(27), '광양시': np.int64(28), '광주시': np.int64(29), '광진구': np.int64(30), '괴산군': np.int64(31), '구례군': np.int64(32), '구로구': np.int64(33), '구리시': np.int64(34), '구미시': np.int64(35), '군산시': np.int64(36), '군위군': np.int64(37), '군포시': np.int64(38), '금산군': np.int64(39), '금정구': np.int64(40), '금천구': np.int64(41), '기장군': np.int64(42), '김제시': np.int64(43), '김천시': np.int64(44), '김포시': np.int64(45), '김해시': np.int64(46), '나주시': np.int64(47), '남구': np.int64(48), '남동구': np.int64(49), '남양주시': np.int64(50), '남원시': np.int64(51), '남해군': np.int64(52), '노원구': np.int64(53), '논산시': np.int64(54), '단양군': np.int64(55), '달서구': np.int64(56), '달성군': np.int64(57), '담양군': np.int64(58), '당진시': np.int64(59), '대덕구': np.int64(60), '도봉구': np.int64(61), '동구': np.int64(62), '동대문구': np.int64(63), '동두천시': np.int64(64), '동래구': np.int64(65), '동작구': np.int64(66), '동해시': np.int64(67), '마포구': np.int64(68), '목포시': np.int64(69), '무안군': np.int64(70), '무주군': np.int64(71), '문경시': np.int64(72), '밀양시': np.int64(73), '보령시': np.int64(74), '보성군': np.int64(75), '보은군': np.int64(76), '봉화군': np.int64(77), '부산진구': np.int64(78), '부안군': np.int64(79), '부여군': np.int64(80), '부평구': np.int64(81), '북구': np.int64(82), '사상구': np.int64(83), '사천시': np.int64(84), '사하구': np.int64(85), '산청군': np.int64(86), '삼척시': np.int64(87), '상주시': np.int64(88), '서구': np.int64(89), '서귀포시': np.int64(90), '서대문구': np.int64(91), '서산시': np.int64(92), '서천군': np.int64(93), '서초구': np.int64(94), '성남시 분당구': np.int64(95), '성남시 수정구': np.int64(96), '성남시 중원구': np.int64(97), '성북구': np.int64(98), '성주군': np.int64(99), '속초시': np.int64(100), '송파구': np.int64(101), '수성구': np.int64(102), '수영구': np.int64(103), '수원시 권선구': np.int64(104), '수원시 영통구': np.int64(105), '수원시 장안구': np.int64(106), '순창군': np.int64(107), '순천시': np.int64(108), '시흥시': np.int64(109), '신안군': np.int64(110), '아산시': np.int64(111), '안동시': np.int64(112), '안산시 단원구': np.int64(113), '안산시 상록구': np.int64(114), '안성시': np.int64(115), '안양시 동안구': np.int64(116), '안양시 만안구': np.int64(117), '양구군': np.int64(118), '양산시': np.int64(119), '양양군': np.int64(120), '양주시': np.int64(121), '양천구': np.int64(122), '양평군': np.int64(123), '여수시': np.int64(124), '여주시': np.int64(125), '연수구': np.int64(126), '연제구': np.int64(127), '연천군': np.int64(128), '영광군': np.int64(129), '영덕군': np.int64(130), '영도구': np.int64(131), '영동군': np.int64(132), '영암군': np.int64(133), '영양군': np.int64(134), '영월군': np.int64(135), '영주시': np.int64(136), '영천시': np.int64(137), '예산군': np.int64(138), '예천군': np.int64(139), '오산시': np.int64(140), '옥천군': np.int64(141), '옹진군': np.int64(142), '완도군': np.int64(143), '완주군': np.int64(144), '용산구': np.int64(145), '용인시 기흥구': np.int64(146), '용인시 수지구': np.int64(147), '용인시 처인구': np.int64(148), '울릉군': np.int64(149), '울주군': np.int64(150), '울진군': np.int64(151), '원주시': np.int64(152), '유성구': np.int64(153), '은평구': np.int64(154), '음성군': np.int64(155), '의령군': np.int64(156), '의성군': np.int64(157), '의왕시': np.int64(158), '의정부시': np.int64(159), '이천시': np.int64(160), '익산시': np.int64(161), '인제군': np.int64(162), '임실군': np.int64(163), '장성군': np.int64(164), '장수군': np.int64(165), '장흥군': np.int64(166), '전주시 완산구': np.int64(167), '정선군': np.int64(168), '정읍시': np.int64(169), '제주시': np.int64(170), '제천시': np.int64(171), '종로구': np.int64(172), '중구': np.int64(173), '중랑구': np.int64(174), '증평군': np.int64(175), '진도군': np.int64(176), '진안군': np.int64(177), '진주시': np.int64(178), '진천군': np.int64(179), '창녕군': np.int64(180), '창원시 마산합포구': np.int64(181), '창원시 마산회원구': np.int64(182), '창원시 성산구': np.int64(183), '창원시 의창구': np.int64(184), '창원시 진해구': np.int64(185), '천안시 동남구': np.int64(186), '천안시 서북구': np.int64(187), '철원군': np.int64(188), '청도군': np.int64(189), '청송군': np.int64(190), '청양군': np.int64(191), '청주시 상당구': np.int64(192), '청주시 서원구': np.int64(193), '청주시 청원구': np.int64(194), '청주시 흥덕구': np.int64(195), '춘천시': np.int64(196), '충주시': np.int64(197), '칠곡군': np.int64(198), '태백시': np.int64(199), '태안군': np.int64(200), '통영시': np.int64(201), '파주시': np.int64(202), '평창군': np.int64(203), '평택시': np.int64(204), '포천시': np.int64(205), '포항시 남구': np.int64(206), '포항시 북구': np.int64(207), '하남시': np.int64(208), '하동군': np.int64(209), '함안군': np.int64(210), '함양군': np.int64(211), '함평군': np.int64(212), '합천군': np.int64(213), '해남군': np.int64(214), '해운대구': np.int64(215), '홍성군': np.int64(216), '홍천군': np.int64(217), '화성시': np.int64(218), '화순군': np.int64(219), '화천군': np.int64(220), '횡성군': np.int64(221)}\n",
      "고유값 개수: 222\n",
      "\n",
      "[CTPV_NM] 레이블 인코딩 중...\n",
      "매칭 테이블: {'강원특별자치도': np.int64(0), '경기도': np.int64(1), '경상남도': np.int64(2), '경상북도': np.int64(3), '광주광역시': np.int64(4), '대구광역시': np.int64(5), '대전광역시': np.int64(6), '부산광역시': np.int64(7), '서울특별시': np.int64(8), '세종특별자치시': np.int64(9), '울산광역시': np.int64(10), '인천광역시': np.int64(11), '전라남도': np.int64(12), '전북특별자치도': np.int64(13), '제주특별자치도': np.int64(14), '충청남도': np.int64(15), '충청북도': np.int64(16)}\n",
      "고유값 개수: 17\n",
      "\n",
      "[FCLT_PLC_SCLSF_NM] 레이블 인코딩 중...\n",
      "매칭 테이블: {'공유림': np.int64(0), '국유림': np.int64(1), '사유림': np.int64(2)}\n",
      "고유값 개수: 3\n",
      "\n",
      "[FND_IGTN_PSTN_NM] 레이블 인코딩 중...\n",
      "매칭 테이블: {'미상': np.int64(0), '산아래': np.int64(1), '산정상': np.int64(2), '산중턱': np.int64(3), '평지': np.int64(4)}\n",
      "고유값 개수: 5\n",
      "\n",
      "[FND_FIRE_SE_NM] 레이블 인코딩 중...\n",
      "매칭 테이블: {'공유림': np.int64(0), '국유림': np.int64(1), '사유림': np.int64(2)}\n",
      "고유값 개수: 3\n",
      "\n",
      "[WNDRCT_BRNG] 레이블 인코딩 중...\n",
      "매칭 테이블: {'NONE': np.int64(0), '남': np.int64(1), '남동': np.int64(2), '남서': np.int64(3), '동': np.int64(4), '북': np.int64(5), '북동': np.int64(6), '북서': np.int64(7), '서': np.int64(8)}\n",
      "고유값 개수: 9\n",
      "\n",
      "=== 레이블 인코딩 완료 ===\n",
      "처리된 데이터 크기: (3560, 17)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 레이블 인코딩용 데이터프레임 생성\n",
    "df_label_encoded = df_lfdau_processed.copy()\n",
    "\n",
    "# 레이블 인코딩할 컬럼들\n",
    "label_columns = ['SGG_NM', 'CTPV_NM', 'FCLT_PLC_SCLSF_NM', 'FND_IGTN_PSTN_NM', 'FND_FIRE_SE_NM', 'WNDRCT_BRNG']\n",
    "\n",
    "print(\"=== 레이블 인코딩 진행 ===\")\n",
    "\n",
    "# 각 컬럼별 레이블 인코더 저장용\n",
    "label_encoders = {}\n",
    "\n",
    "for col in label_columns:\n",
    "    if col in df_label_encoded.columns:\n",
    "        print(f\"\\n[{col}] 레이블 인코딩 중...\")\n",
    "        \n",
    "        # 레이블 인코더 생성 및 피팅\n",
    "        le = LabelEncoder()\n",
    "        df_label_encoded[col] = le.fit_transform(df_label_encoded[col].astype(str))\n",
    "        \n",
    "        # 인코더 저장 (나중에 역변환 가능)\n",
    "        label_encoders[col] = le\n",
    "        \n",
    "        # 매칭 테이블 출력\n",
    "        mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "        print(f\"매칭 테이블: {dict(sorted(mapping.items()))}\")\n",
    "        print(f\"고유값 개수: {len(le.classes_)}\")\n",
    "    else:\n",
    "        print(f\"\\n[{col}] 컬럼이 존재하지 않습니다.\")\n",
    "\n",
    "print(f\"\\n=== 레이블 인코딩 완료 ===\")\n",
    "print(f\"처리된 데이터 크기: {df_label_encoded.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0629daf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== HR_UNIT_WSPD_INFO 컬럼 고유값 확인 ===\n",
      "고유값 개수: 6\n",
      "고유값 목록:\n",
      "['0~4 m/s' '9~12 m/s' '18 m/s 이상' '5~8 m/s' 'NONE' '13~17 m/s']\n",
      "\n",
      "값별 개수:\n",
      "HR_UNIT_WSPD_INFO\n",
      "0~4 m/s      2865\n",
      "5~8 m/s       418\n",
      "NONE          186\n",
      "9~12 m/s       56\n",
      "13~17 m/s      21\n",
      "18 m/s 이상      14\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# HR_UNIT_WSPD_INFO 컬럼의 고유값 확인\n",
    "print(\"=== HR_UNIT_WSPD_INFO 컬럼 고유값 확인 ===\")\n",
    "print(f\"고유값 개수: {df_label_encoded['HR_UNIT_WSPD_INFO'].nunique()}\")\n",
    "print(f\"고유값 목록:\")\n",
    "print(df_label_encoded['HR_UNIT_WSPD_INFO'].unique())\n",
    "print(f\"\\n값별 개수:\")\n",
    "print(df_label_encoded['HR_UNIT_WSPD_INFO'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "798eca80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== HR_UNIT_WSPD_INFO 컬럼 수치 변환 ===\n",
      "변환 전 고유값:\n",
      "HR_UNIT_WSPD_INFO\n",
      "0~4 m/s      2865\n",
      "5~8 m/s       418\n",
      "NONE          186\n",
      "9~12 m/s       56\n",
      "13~17 m/s      21\n",
      "18 m/s 이상      14\n",
      "Name: count, dtype: int64\n",
      "\n",
      "변환 후 고유값:\n",
      "HR_UNIT_WSPD_INFO\n",
      "-1.0      186\n",
      " 2.0     2865\n",
      " 6.5      418\n",
      " 10.5      56\n",
      " 15.0      21\n",
      " 20.0      14\n",
      "Name: count, dtype: int64\n",
      "\n",
      "매핑 테이블:\n",
      "'0~4 m/s' → 2.0\n",
      "'5~8 m/s' → 6.5\n",
      "'9~12 m/s' → 10.5\n",
      "'13~17 m/s' → 15.0\n",
      "'18 m/s 이상' → 20.0\n",
      "'NONE' → -1.0\n",
      "\n",
      "처리된 데이터 크기: (3560, 17)\n"
     ]
    }
   ],
   "source": [
    "# HR_UNIT_WSPD_INFO 컬럼 수치 변환용 데이터프레임 생성\n",
    "df_wspd_processed = df_label_encoded.copy()\n",
    "\n",
    "print(\"=== HR_UNIT_WSPD_INFO 컬럼 수치 변환 ===\")\n",
    "\n",
    "# 변환 전 상태 확인\n",
    "print(\"변환 전 고유값:\")\n",
    "print(df_wspd_processed['HR_UNIT_WSPD_INFO'].value_counts())\n",
    "\n",
    "# 풍속 범위를 평균값으로 변환하는 매핑 딕셔너리\n",
    "wspd_mapping = {\n",
    "    '0~4 m/s': 2.0,\n",
    "    '5~8 m/s': 6.5,\n",
    "    '9~12 m/s': 10.5,\n",
    "    '13~17 m/s': 15.0,\n",
    "    '18 m/s 이상': 20.0,  # 18 이상이므로 추정값\n",
    "    'NONE': -1.0\n",
    "}\n",
    "\n",
    "# 매핑 적용\n",
    "df_wspd_processed['HR_UNIT_WSPD_INFO'] = df_wspd_processed['HR_UNIT_WSPD_INFO'].map(wspd_mapping)\n",
    "\n",
    "# 변환 후 상태 확인\n",
    "print(f\"\\n변환 후 고유값:\")\n",
    "print(df_wspd_processed['HR_UNIT_WSPD_INFO'].value_counts().sort_index())\n",
    "\n",
    "print(f\"\\n매핑 테이블:\")\n",
    "for key, value in wspd_mapping.items():\n",
    "    print(f\"'{key}' → {value}\")\n",
    "\n",
    "print(f\"\\n처리된 데이터 크기: {df_wspd_processed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "db45efe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 시각 관련 컬럼 데이터 타입 확인 ===\n",
      "\n",
      "[RCPT_DT]\n",
      "데이터 타입: int64\n",
      "샘플 값:\n",
      "[20190120042323, 20190311043409, 20190306020227]\n",
      "\n",
      "[DSPT_DT]\n",
      "데이터 타입: int64\n",
      "샘플 값:\n",
      "[20190120042454, 20190311043447, 20190306020300]\n",
      "\n",
      "[GRNDS_ARVL_DT]\n",
      "데이터 타입: int64\n",
      "샘플 값:\n",
      "[20190120042900, 20190311043900, 20190306021343]\n"
     ]
    }
   ],
   "source": [
    "# 시각 관련 컬럼들의 데이터 타입 확인\n",
    "print(\"=== 시각 관련 컬럼 데이터 타입 확인 ===\")\n",
    "\n",
    "time_columns = ['RCPT_DT', 'DSPT_DT', 'GRNDS_ARVL_DT']\n",
    "\n",
    "for col in time_columns:\n",
    "    if col in df_wspd_processed.columns:\n",
    "        print(f\"\\n[{col}]\")\n",
    "        print(f\"데이터 타입: {df_wspd_processed[col].dtype}\")\n",
    "        print(f\"샘플 값:\")\n",
    "        print(df_wspd_processed[col].head(3).tolist())\n",
    "    else:\n",
    "        print(f\"\\n[{col}] 컬럼이 존재하지 않습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dce01a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 시각 관련 컬럼 datetime 변환 ===\n",
      "\n",
      "[RCPT_DT] 변환 중...\n",
      "변환 전 타입: int64\n",
      "변환 전 샘플: [20190120042323, 20190311043409]\n",
      "변환 후 타입: datetime64[ns]\n",
      "변환 후 샘플: [Timestamp('2019-01-20 04:23:23'), Timestamp('2019-03-11 04:34:09')]\n",
      "변환 실패(NaT) 개수: 0\n",
      "\n",
      "[DSPT_DT] 변환 중...\n",
      "변환 전 타입: int64\n",
      "변환 전 샘플: [20190120042454, 20190311043447]\n",
      "변환 후 타입: datetime64[ns]\n",
      "변환 후 샘플: [Timestamp('2019-01-20 04:24:54'), Timestamp('2019-03-11 04:34:47')]\n",
      "변환 실패(NaT) 개수: 0\n",
      "\n",
      "[GRNDS_ARVL_DT] 변환 중...\n",
      "변환 전 타입: int64\n",
      "변환 전 샘플: [20190120042900, 20190311043900]\n",
      "변환 후 타입: datetime64[ns]\n",
      "변환 후 샘플: [Timestamp('2019-01-20 04:29:00'), Timestamp('2019-03-11 04:39:00')]\n",
      "변환 실패(NaT) 개수: 0\n",
      "\n",
      "=== datetime 변환 완료 ===\n",
      "처리된 데이터 크기: (3560, 17)\n"
     ]
    }
   ],
   "source": [
    "# 시각 컬럼 datetime 변환용 데이터프레임 생성\n",
    "df_datetime_processed = df_wspd_processed.copy()\n",
    "\n",
    "print(\"=== 시각 관련 컬럼 datetime 변환 ===\")\n",
    "\n",
    "# 변환할 시각 컬럼들\n",
    "time_columns = ['RCPT_DT', 'DSPT_DT', 'GRNDS_ARVL_DT']\n",
    "\n",
    "for col in time_columns:\n",
    "    if col in df_datetime_processed.columns:\n",
    "        print(f\"\\n[{col}] 변환 중...\")\n",
    "        \n",
    "        # 변환 전 상태\n",
    "        print(f\"변환 전 타입: {df_datetime_processed[col].dtype}\")\n",
    "        print(f\"변환 전 샘플: {df_datetime_processed[col].head(2).tolist()}\")\n",
    "        \n",
    "        # datetime 변환\n",
    "        df_datetime_processed[col] = pd.to_datetime(\n",
    "            df_datetime_processed[col].astype(str), \n",
    "            format='%Y%m%d%H%M%S', \n",
    "            errors='coerce'\n",
    "        )\n",
    "        \n",
    "        # 변환 후 상태\n",
    "        print(f\"변환 후 타입: {df_datetime_processed[col].dtype}\")\n",
    "        print(f\"변환 후 샘플: {df_datetime_processed[col].head(2).tolist()}\")\n",
    "        print(f\"변환 실패(NaT) 개수: {df_datetime_processed[col].isnull().sum()}\")\n",
    "    else:\n",
    "        print(f\"\\n[{col}] 컬럼이 존재하지 않습니다.\")\n",
    "\n",
    "print(f\"\\n=== datetime 변환 완료 ===\")\n",
    "print(f\"처리된 데이터 크기: {df_datetime_processed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7880f5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 전처리 과정 검토 ===\n",
      "1. 원본 데이터:\n",
      "   - 크기: (3560, 47)\n",
      "\n",
      "2. 컬럼 제거 후:\n",
      "   - 크기: (3560, 17)\n",
      "   - 제거된 컬럼 수: 30\n",
      "\n",
      "3. LFDAU_GRNDS_DSTNC 전처리 후:\n",
      "   - 크기: (3560, 17)\n",
      "   - -1값(missing label) 개수: 2446\n",
      "\n",
      "4. 레이블 인코딩 후:\n",
      "   - 크기: (3560, 17)\n",
      "   - 인코딩된 컬럼: SGG_NM, CTPV_NM, FCLT_PLC_SCLSF_NM, FND_IGTN_PSTN_NM, FND_FIRE_SE_NM, WNDRCT_BRNG\n",
      "\n",
      "5. 풍속 수치 변환 후:\n",
      "   - 크기: (3560, 17)\n",
      "   - HR_UNIT_WSPD_INFO 타입: float64\n",
      "\n",
      "6. 시각 datetime 변환 후:\n",
      "   - 크기: (3560, 17)\n",
      "   - RCPT_DT 타입: datetime64[ns]\n",
      "\n",
      "=== 각 객체 상태 확인 ===\n",
      "df_col_removed 결측치: 46\n",
      "df_datetime_processed 결측치: 0\n"
     ]
    }
   ],
   "source": [
    "# 전처리 과정 간단 검토\n",
    "print(\"=== 전처리 과정 검토 ===\")\n",
    "\n",
    "print(\"1. 원본 데이터:\")\n",
    "print(f\"   - 크기: {df.shape}\")\n",
    "\n",
    "print(\"\\n2. 컬럼 제거 후:\")\n",
    "print(f\"   - 크기: {df_col_removed.shape}\")\n",
    "print(f\"   - 제거된 컬럼 수: {len(df.columns) - len(df_col_removed.columns)}\")\n",
    "\n",
    "print(\"\\n3. LFDAU_GRNDS_DSTNC 전처리 후:\")\n",
    "print(f\"   - 크기: {df_lfdau_processed.shape}\")\n",
    "print(f\"   - -1값(missing label) 개수: {(df_lfdau_processed['LFDAU_GRNDS_DSTNC'] == -1).sum()}\")\n",
    "\n",
    "print(\"\\n4. 레이블 인코딩 후:\")\n",
    "print(f\"   - 크기: {df_label_encoded.shape}\")\n",
    "print(f\"   - 인코딩된 컬럼: SGG_NM, CTPV_NM, FCLT_PLC_SCLSF_NM, FND_IGTN_PSTN_NM, FND_FIRE_SE_NM, WNDRCT_BRNG\")\n",
    "\n",
    "print(\"\\n5. 풍속 수치 변환 후:\")\n",
    "print(f\"   - 크기: {df_wspd_processed.shape}\")\n",
    "print(f\"   - HR_UNIT_WSPD_INFO 타입: {df_wspd_processed['HR_UNIT_WSPD_INFO'].dtype}\")\n",
    "\n",
    "print(\"\\n6. 시각 datetime 변환 후:\")\n",
    "print(f\"   - 크기: {df_datetime_processed.shape}\")\n",
    "print(f\"   - RCPT_DT 타입: {df_datetime_processed['RCPT_DT'].dtype}\")\n",
    "\n",
    "print(\"\\n=== 각 객체 상태 확인 ===\")\n",
    "print(f\"df_col_removed 결측치: {df_col_removed.isnull().sum().sum()}\")\n",
    "print(f\"df_datetime_processed 결측치: {df_datetime_processed.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c9b58a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DSPT_REQ_HR 컬럼 값 분석 ===\n",
      "데이터 타입: int64\n",
      "고유값 개수: 1293\n",
      "\n",
      "샘플 값들:\n",
      "[246, 253, 643, 578, 874, 565, 649, 440, 313, 1151]\n",
      "\n",
      "값 범위:\n",
      "최솟값: 0\n",
      "최댓값: 16468\n",
      "\n",
      "값 분포 (상위 10개):\n",
      "DSPT_REQ_HR\n",
      "300    30\n",
      "299    22\n",
      "397    13\n",
      "298    13\n",
      "293    13\n",
      "323    12\n",
      "355    11\n",
      "420    11\n",
      "360    11\n",
      "411    10\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# DSPT_REQ_HR 컬럼 값 확인\n",
    "print(\"=== DSPT_REQ_HR 컬럼 값 분석 ===\")\n",
    "print(f\"데이터 타입: {df_datetime_processed['DSPT_REQ_HR'].dtype}\")\n",
    "print(f\"고유값 개수: {df_datetime_processed['DSPT_REQ_HR'].nunique()}\")\n",
    "\n",
    "print(f\"\\n샘플 값들:\")\n",
    "print(df_datetime_processed['DSPT_REQ_HR'].head(10).tolist())\n",
    "\n",
    "print(f\"\\n값 범위:\")\n",
    "print(f\"최솟값: {df_datetime_processed['DSPT_REQ_HR'].min()}\")\n",
    "print(f\"최댓값: {df_datetime_processed['DSPT_REQ_HR'].max()}\")\n",
    "\n",
    "print(f\"\\n값 분포 (상위 10개):\")\n",
    "print(df_datetime_processed['DSPT_REQ_HR'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e5c1ddf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 파생변수 생성 시작 ===\n",
      "1. golden_time_under_50min 생성 중...\n",
      "   - 골든타임(1) 개수: 3535\n",
      "   - 비골든타임(0) 개수: 25\n",
      "\n",
      "2. arrival_time_diff 생성 중...\n",
      "   - 평균 도착시간: 832.54초\n",
      "   - 최소 도착시간: 0.00초\n",
      "   - 최대 도착시간: 88071.00초\n",
      "\n",
      "3. is_night 생성 중...\n",
      "   - 야간 화재(1) 개수: 439\n",
      "   - 주간 화재(0) 개수: 3121\n",
      "\n",
      "4. month_rcpt 생성 중...\n",
      "   - 월별 분포:\n",
      "month_rcpt\n",
      "1     367\n",
      "2     510\n",
      "3     809\n",
      "4     837\n",
      "5     353\n",
      "6     122\n",
      "7      45\n",
      "8      16\n",
      "9      31\n",
      "10    106\n",
      "11    179\n",
      "12    185\n",
      "Name: count, dtype: int64\n",
      "\n",
      "5. dispatch_time_diff 생성 중...\n",
      "   - 평균 출동시간: 79.89초\n",
      "   - 최소 출동시간: 0.00초\n",
      "   - 최대 출동시간: 5798.00초\n",
      "\n",
      "=== 파생변수 생성 완료 ===\n",
      "처리된 데이터 크기: (3560, 22)\n",
      "새로 생성된 컬럼: ['golden_time_under_50min', 'arrival_time_diff', 'is_night', 'month_rcpt', 'dispatch_time_diff']\n",
      "\n",
      "=== 파생변수 기본 통계 ===\n",
      "       golden_time_under_50min  arrival_time_diff     is_night   month_rcpt  \\\n",
      "count              3560.000000        3560.000000  3560.000000  3560.000000   \n",
      "mean                  0.992978         832.536517     0.123315     4.390449   \n",
      "std                   0.083517        2165.303472     0.328844     3.013190   \n",
      "min                   0.000000           0.000000     0.000000     1.000000   \n",
      "25%                   1.000000         424.750000     0.000000     3.000000   \n",
      "50%                   1.000000         659.000000     0.000000     4.000000   \n",
      "75%                   1.000000         953.000000     0.000000     5.000000   \n",
      "max                   1.000000       88071.000000     1.000000    12.000000   \n",
      "\n",
      "       dispatch_time_diff  \n",
      "count         3560.000000  \n",
      "mean            79.888764  \n",
      "std            122.884099  \n",
      "min              0.000000  \n",
      "25%             46.000000  \n",
      "50%             62.000000  \n",
      "75%             92.000000  \n",
      "max           5798.000000  \n"
     ]
    }
   ],
   "source": [
    "# 파생변수 생성용 데이터프레임 생성\n",
    "df_features_created = df_datetime_processed.copy()\n",
    "\n",
    "print(\"=== 파생변수 생성 시작 ===\")\n",
    "\n",
    "# 1. golden_time_under_50min: 3000초(50분) 이하 골든타임 라벨링\n",
    "print(\"1. golden_time_under_50min 생성 중...\")\n",
    "df_features_created['golden_time_under_50min'] = (df_features_created['DSPT_REQ_HR'] <= 3000).astype(int)\n",
    "print(f\"   - 골든타임(1) 개수: {df_features_created['golden_time_under_50min'].sum()}\")\n",
    "print(f\"   - 비골든타임(0) 개수: {(df_features_created['golden_time_under_50min'] == 0).sum()}\")\n",
    "\n",
    "# 2. arrival_time_diff: 소방차 도착까지 걸린 시간(초)\n",
    "print(\"\\n2. arrival_time_diff 생성 중...\")\n",
    "df_features_created['arrival_time_diff'] = (df_features_created['GRNDS_ARVL_DT'] - df_features_created['RCPT_DT']).dt.total_seconds()\n",
    "print(f\"   - 평균 도착시간: {df_features_created['arrival_time_diff'].mean():.2f}초\")\n",
    "print(f\"   - 최소 도착시간: {df_features_created['arrival_time_diff'].min():.2f}초\")\n",
    "print(f\"   - 최대 도착시간: {df_features_created['arrival_time_diff'].max():.2f}초\")\n",
    "\n",
    "# 3. is_night: 야간 화재 여부 (20:00~06:59)\n",
    "print(\"\\n3. is_night 생성 중...\")\n",
    "df_features_created['is_night'] = ((df_features_created['RCPT_DT'].dt.hour >= 20) | \n",
    "                                   (df_features_created['RCPT_DT'].dt.hour <= 6)).astype(int)\n",
    "print(f\"   - 야간 화재(1) 개수: {df_features_created['is_night'].sum()}\")\n",
    "print(f\"   - 주간 화재(0) 개수: {(df_features_created['is_night'] == 0).sum()}\")\n",
    "\n",
    "# 4. month_rcpt: 신고 월 추출\n",
    "print(\"\\n4. month_rcpt 생성 중...\")\n",
    "df_features_created['month_rcpt'] = df_features_created['RCPT_DT'].dt.month\n",
    "print(f\"   - 월별 분포:\")\n",
    "print(df_features_created['month_rcpt'].value_counts().sort_index())\n",
    "\n",
    "# 5. dispatch_time_diff: 출동까지 걸린 시간(초)\n",
    "print(\"\\n5. dispatch_time_diff 생성 중...\")\n",
    "df_features_created['dispatch_time_diff'] = (df_features_created['DSPT_DT'] - df_features_created['RCPT_DT']).dt.total_seconds()\n",
    "print(f\"   - 평균 출동시간: {df_features_created['dispatch_time_diff'].mean():.2f}초\")\n",
    "print(f\"   - 최소 출동시간: {df_features_created['dispatch_time_diff'].min():.2f}초\")\n",
    "print(f\"   - 최대 출동시간: {df_features_created['dispatch_time_diff'].max():.2f}초\")\n",
    "\n",
    "print(f\"\\n=== 파생변수 생성 완료 ===\")\n",
    "print(f\"처리된 데이터 크기: {df_features_created.shape}\")\n",
    "print(f\"새로 생성된 컬럼: {[col for col in df_features_created.columns if col not in df_datetime_processed.columns]}\")\n",
    "\n",
    "# 생성된 파생변수들의 기본 통계 확인\n",
    "print(f\"\\n=== 파생변수 기본 통계 ===\")\n",
    "print(df_features_created[['golden_time_under_50min', 'arrival_time_diff', 'is_night', 'month_rcpt', 'dispatch_time_diff']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d6a35577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 음수 값 확인 ===\n",
      "arrival_time_diff:\n",
      "  - 음수 개수: 0\n",
      "  - 음수 값들: []\n",
      "\n",
      "dispatch_time_diff:\n",
      "  - 음수 개수: 0\n",
      "  - 음수 값들: []\n"
     ]
    }
   ],
   "source": [
    "# 음수 값 확인\n",
    "print(\"=== 음수 값 확인 ===\")\n",
    "\n",
    "print(\"arrival_time_diff:\")\n",
    "print(f\"  - 음수 개수: {(df_features_created['arrival_time_diff'] < 0).sum()}\")\n",
    "print(f\"  - 음수 값들: {df_features_created[df_features_created['arrival_time_diff'] < 0]['arrival_time_diff'].tolist()}\")\n",
    "\n",
    "print(\"\\ndispatch_time_diff:\")\n",
    "print(f\"  - 음수 개수: {(df_features_created['dispatch_time_diff'] < 0).sum()}\")\n",
    "print(f\"  - 음수 값들: {df_features_created[df_features_created['dispatch_time_diff'] < 0]['dispatch_time_diff'].tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0991aa69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 최종 전처리 - 시각 관련 컬럼 제거 ===\n",
      "제거 전:\n",
      "- 데이터 크기: (3560, 22)\n",
      "- 제거할 컬럼: ['RCPT_DT', 'DSPT_DT', 'GRNDS_ARVL_DT']\n",
      "\n",
      "제거 후:\n",
      "- 데이터 크기: (3560, 19)\n",
      "- 남은 컬럼 수: 19\n",
      "\n",
      "=== 최종 전처리 완료 ===\n",
      "최종 데이터프레임: df_processed\n",
      "최종 크기: (3560, 19)\n"
     ]
    }
   ],
   "source": [
    "# 최종 전처리용 데이터프레임 생성\n",
    "df_processed = df_features_created.copy()\n",
    "\n",
    "print(\"=== 최종 전처리 - 시각 관련 컬럼 제거 ===\")\n",
    "\n",
    "# 제거할 시각 관련 컬럼들\n",
    "time_columns_to_remove = ['RCPT_DT', 'DSPT_DT', 'GRNDS_ARVL_DT']\n",
    "\n",
    "print(\"제거 전:\")\n",
    "print(f\"- 데이터 크기: {df_processed.shape}\")\n",
    "print(f\"- 제거할 컬럼: {time_columns_to_remove}\")\n",
    "\n",
    "# 컬럼 제거\n",
    "df_processed = df_processed.drop(columns=time_columns_to_remove, errors='ignore')\n",
    "\n",
    "print(\"\\n제거 후:\")\n",
    "print(f\"- 데이터 크기: {df_processed.shape}\")\n",
    "print(f\"- 남은 컬럼 수: {len(df_processed.columns)}\")\n",
    "\n",
    "print(f\"\\n=== 최종 전처리 완료 ===\")\n",
    "print(f\"최종 데이터프레임: df_processed\")\n",
    "print(f\"최종 크기: {df_processed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "397c2e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 전처리 과정 전체 검토 ===\n",
      "1. 원본 데이터:\n",
      "   - 크기: (3560, 47)\n",
      "   - 컬럼 수: 47\n",
      "\n",
      "2. 컬럼 제거 후:\n",
      "   - 크기: (3560, 17)\n",
      "   - 제거된 컬럼 수: 30\n",
      "   - 남은 컬럼 수: 17\n",
      "\n",
      "3. LFDAU_GRNDS_DSTNC 전처리 후:\n",
      "   - 크기: (3560, 17)\n",
      "   - -1값(missing label) 개수: 2446\n",
      "\n",
      "4. 레이블 인코딩 후:\n",
      "   - 크기: (3560, 17)\n",
      "   - 인코딩된 컬럼: SGG_NM, CTPV_NM, FCLT_PLC_SCLSF_NM, FND_IGTN_PSTN_NM, FND_FIRE_SE_NM, WNDRCT_BRNG\n",
      "\n",
      "5. 풍속 수치 변환 후:\n",
      "   - 크기: (3560, 17)\n",
      "   - HR_UNIT_WSPD_INFO 타입: float64\n",
      "\n",
      "6. 시각 datetime 변환 후:\n",
      "   - 크기: (3560, 17)\n",
      "   - RCPT_DT 타입: datetime64[ns]\n",
      "\n",
      "7. 파생변수 생성 후:\n",
      "   - 크기: (3560, 22)\n",
      "   - 새로 생성된 컬럼: golden_time_under_50min, arrival_time_diff, is_night, month_rcpt, dispatch_time_diff\n",
      "\n",
      "8. 최종 전처리 완료:\n",
      "   - 크기: (3560, 19)\n",
      "   - 최종 컬럼 수: 19\n",
      "\n",
      "=== 최종 데이터프레임 정보 ===\n",
      "데이터 크기: (3560, 19)\n",
      "데이터 타입:\n",
      "int64      12\n",
      "float64     6\n",
      "int32       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== 결측치 현황 ===\n",
      "결측치가 없습니다!\n",
      "\n",
      "=== 최종 컬럼 목록 ===\n",
      " 1. DSPT_REQ_HR\n",
      " 2. FIRE_SUPESN_HR\n",
      " 3. CTPV_NM\n",
      " 4. SGG_NM\n",
      " 5. FRSTN_GRNDS_DSTNC\n",
      " 6. CNTR_GRNDS_DSTNC\n",
      " 7. LFDAU_GRNDS_DSTNC\n",
      " 8. FCLT_PLC_SCLSF_NM\n",
      " 9. FND_FIRE_SE_NM\n",
      "10. FND_IGTN_PSTN_NM\n",
      "11. HR_UNIT_ARTMP\n",
      "12. HR_UNIT_WSPD_INFO\n",
      "13. WNDRCT_BRNG\n",
      "14. HR_UNIT_HUM\n",
      "15. golden_time_under_50min\n",
      "16. arrival_time_diff\n",
      "17. is_night\n",
      "18. month_rcpt\n",
      "19. dispatch_time_diff\n"
     ]
    }
   ],
   "source": [
    "# 전처리 과정 전체 검토\n",
    "print(\"=== 전처리 과정 전체 검토 ===\")\n",
    "\n",
    "print(\"1. 원본 데이터:\")\n",
    "print(f\"   - 크기: {df.shape}\")\n",
    "print(f\"   - 컬럼 수: {len(df.columns)}\")\n",
    "\n",
    "print(\"\\n2. 컬럼 제거 후:\")\n",
    "print(f\"   - 크기: {df_col_removed.shape}\")\n",
    "print(f\"   - 제거된 컬럼 수: {len(df.columns) - len(df_col_removed.columns)}\")\n",
    "print(f\"   - 남은 컬럼 수: {len(df_col_removed.columns)}\")\n",
    "\n",
    "print(\"\\n3. LFDAU_GRNDS_DSTNC 전처리 후:\")\n",
    "print(f\"   - 크기: {df_lfdau_processed.shape}\")\n",
    "print(f\"   - -1값(missing label) 개수: {(df_lfdau_processed['LFDAU_GRNDS_DSTNC'] == -1).sum()}\")\n",
    "\n",
    "print(\"\\n4. 레이블 인코딩 후:\")\n",
    "print(f\"   - 크기: {df_label_encoded.shape}\")\n",
    "print(f\"   - 인코딩된 컬럼: SGG_NM, CTPV_NM, FCLT_PLC_SCLSF_NM, FND_IGTN_PSTN_NM, FND_FIRE_SE_NM, WNDRCT_BRNG\")\n",
    "\n",
    "print(\"\\n5. 풍속 수치 변환 후:\")\n",
    "print(f\"   - 크기: {df_wspd_processed.shape}\")\n",
    "print(f\"   - HR_UNIT_WSPD_INFO 타입: {df_wspd_processed['HR_UNIT_WSPD_INFO'].dtype}\")\n",
    "\n",
    "print(\"\\n6. 시각 datetime 변환 후:\")\n",
    "print(f\"   - 크기: {df_datetime_processed.shape}\")\n",
    "print(f\"   - RCPT_DT 타입: {df_datetime_processed['RCPT_DT'].dtype}\")\n",
    "\n",
    "print(\"\\n7. 파생변수 생성 후:\")\n",
    "print(f\"   - 크기: {df_features_created.shape}\")\n",
    "print(f\"   - 새로 생성된 컬럼: golden_time_under_50min, arrival_time_diff, is_night, month_rcpt, dispatch_time_diff\")\n",
    "\n",
    "print(\"\\n8. 최종 전처리 완료:\")\n",
    "print(f\"   - 크기: {df_processed.shape}\")\n",
    "print(f\"   - 최종 컬럼 수: {len(df_processed.columns)}\")\n",
    "\n",
    "print(\"\\n=== 최종 데이터프레임 정보 ===\")\n",
    "print(f\"데이터 크기: {df_processed.shape}\")\n",
    "print(f\"데이터 타입:\")\n",
    "print(df_processed.dtypes.value_counts())\n",
    "\n",
    "print(f\"\\n=== 결측치 현황 ===\")\n",
    "missing_count = df_processed.isnull().sum()\n",
    "if missing_count.sum() > 0:\n",
    "    print(\"결측치가 있는 컬럼:\")\n",
    "    print(missing_count[missing_count > 0])\n",
    "else:\n",
    "    print(\"결측치가 없습니다!\")\n",
    "\n",
    "print(f\"\\n=== 최종 컬럼 목록 ===\")\n",
    "for i, col in enumerate(df_processed.columns, 1):\n",
    "    print(f\"{i:2d}. {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4defaf52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CSV 저장 시작 ===\n",
      "저장할 파일명: preprocessed_wildfire_20250816.csv\n",
      "저장할 데이터 크기: (3560, 19)\n",
      "\n",
      "=== CSV 저장 완료 ===\n",
      "파일이 성공적으로 저장되었습니다: preprocessed_wildfire_20250816.csv\n",
      "파일 크기: 0.22 MB\n",
      "저장 경로: /Users/snu.sim/workspace/DL /preprocessed_wildfire_20250816.csv\n"
     ]
    }
   ],
   "source": [
    "# 최종 전처리된 데이터를 CSV로 저장\n",
    "from datetime import datetime\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d\")\n",
    "output_filename = f\"preprocessed_wildfire_{timestamp}.csv\"\n",
    "\n",
    "print(\"=== CSV 저장 시작 ===\")\n",
    "print(f\"저장할 파일명: {output_filename}\")\n",
    "print(f\"저장할 데이터 크기: {df_processed.shape}\")\n",
    "\n",
    "# CSV 저장\n",
    "df_processed.to_csv(output_filename, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"\\n=== CSV 저장 완료 ===\")\n",
    "print(f\"파일이 성공적으로 저장되었습니다: {output_filename}\")\n",
    "\n",
    "# 저장된 파일 정보 확인\n",
    "import os\n",
    "if os.path.exists(output_filename):\n",
    "    file_size = os.path.getsize(output_filename) / (1024 * 1024)  # MB 단위\n",
    "    print(f\"파일 크기: {file_size:.2f} MB\")\n",
    "    print(f\"저장 경로: {os.path.abspath(output_filename)}\")\n",
    "else:\n",
    "    print(\"파일 저장에 실패했습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a42db42",
   "metadata": {},
   "source": [
    "## LOG 변환을 위한 EDA 및 추가 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e784901",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.font_manager as fm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 한글 폰트 설정 (문제 해결 버전)\n",
    "print(\"=== 폰트 설정 시작 ===\")\n",
    "\n",
    "# 시스템에 설치된 폰트 확인\n",
    "available_fonts = [f.name for f in fm.fontManager.ttflist]\n",
    "korean_fonts = [f for f in available_fonts if any(k in f for k in ['Gothic', 'Malgun', 'Nanum', 'Batang', 'Dotum', 'Apple'])]\n",
    "\n",
    "print(f\"사용 가능한 한글 관련 폰트: {korean_fonts[:5]}\")\n",
    "\n",
    "# 한글 폰트 설정\n",
    "if korean_fonts:\n",
    "    selected_font = korean_fonts[0]\n",
    "    plt.rcParams['font.family'] = selected_font\n",
    "    print(f\"선택된 폰트: {selected_font}\")\n",
    "else:\n",
    "    # 한글 폰트가 없으면 기본 폰트 사용\n",
    "    plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "    print(\"한글 폰트를 찾을 수 없어 기본 폰트를 사용합니다.\")\n",
    "\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 폰트 설정 확인\n",
    "print(f\"현재 설정된 폰트: {plt.rcParams['font.family']}\")\n",
    "\n",
    "# 그래프 스타일 설정\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# 분석할 변수들\n",
    "variables_to_plot = [\n",
    "    \"FIRE_SUPESN_HR\",        # 타겟 변수\n",
    "    \"DSPT_REQ_HR\",          # 출동 요청 시간\n",
    "    \"FRSTN_GRNDS_DSTNC\",    # 산림지역 거리\n",
    "    \"CNTR_GRNDS_DSTNC\",     # 중심지역 거리\n",
    "    \"LFDAU_GRNDS_DSTNC\",    # 인접지역 거리\n",
    "    \"arrival_time_diff\",     # 도착 시간 차이\n",
    "    \"dispatch_time_diff\"     # 출동 시간 차이\n",
    "]\n",
    "\n",
    "# 1. 기본 통계 정보 출력\n",
    "print(\"\\n=== 변수별 기본 통계 정보 ===\")\n",
    "for var in variables_to_plot:\n",
    "    if var in df_processed.columns:\n",
    "        print(f\"\\n{var}:\")\n",
    "        print(df_processed[var].describe())\n",
    "    else:\n",
    "        print(f\"\\n{var}: 컬럼이 존재하지 않습니다.\")\n",
    "\n",
    "# 2. 히스토그램과 박스플롯 그리기\n",
    "fig, axes = plt.subplots(4, 2, figsize=(15, 20))\n",
    "fig.suptitle('Fire Data Variable Distribution Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 각 변수별로 그래프 그리기\n",
    "for i, var in enumerate(variables_to_plot):\n",
    "    if var in df_processed.columns:\n",
    "        row = i // 2\n",
    "        col = i % 2\n",
    "        \n",
    "        # 히스토그램\n",
    "        axes[row, col].hist(df_processed[var], bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "        axes[row, col].set_title(f'{var} - Histogram', fontsize=12, fontweight='bold')\n",
    "        axes[row, col].set_xlabel('Value')\n",
    "        axes[row, col].set_ylabel('Frequency')\n",
    "        axes[row, col].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 통계 정보 텍스트로 표시\n",
    "        mean_val = df_processed[var].mean()\n",
    "        std_val = df_processed[var].std()\n",
    "        median_val = df_processed[var].median()\n",
    "        axes[row, col].text(0.02, 0.98, \n",
    "                           f'Mean: {mean_val:.2f}\\nStd: {std_val:.2f}\\nMedian: {median_val:.2f}',\n",
    "                           transform=axes[row, col].transAxes, \n",
    "                           verticalalignment='top',\n",
    "                           bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "# 마지막 subplot 제거 (7개 변수이므로)\n",
    "if len(variables_to_plot) % 2 == 1:\n",
    "    fig.delaxes(axes[3, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3. 박스플롯으로 이상치 확인\n",
    "fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
    "fig.suptitle('Variable Boxplots (Outlier Detection)', fontsize=16, fontweight='bold')\n",
    "\n",
    "for i, var in enumerate(variables_to_plot):\n",
    "    if var in df_processed.columns:\n",
    "        row = i // 4\n",
    "        col = i % 4\n",
    "        \n",
    "        # 박스플롯\n",
    "        axes[row, col].boxplot(df_processed[var], patch_artist=True, \n",
    "                              boxprops=dict(facecolor='lightblue', alpha=0.7))\n",
    "        axes[row, col].set_title(f'{var}', fontsize=12, fontweight='bold')\n",
    "        axes[row, col].set_ylabel('Value')\n",
    "        axes[row, col].grid(True, alpha=0.3)\n",
    "\n",
    "# 마지막 subplot 제거\n",
    "if len(variables_to_plot) % 4 != 0:\n",
    "    for i in range(len(variables_to_plot) % 4, 4):\n",
    "        fig.delaxes(axes[1, i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4. 상관관계 히트맵\n",
    "print(\"\\n=== Variable Correlation Analysis ===\")\n",
    "correlation_data = df_processed[variables_to_plot].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_data, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=0.5, cbar_kws={\"shrink\": .8})\n",
    "plt.title('Variable Correlation Heatmap', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5. 타겟 변수(FIRE_SUPESN_HR)와 다른 변수들의 관계\n",
    "print(\"\\n=== Target Variable (FIRE_SUPESN_HR) Correlation ===\")\n",
    "target_corr = correlation_data['FIRE_SUPESN_HR'].sort_values(ascending=False)\n",
    "print(target_corr)\n",
    "\n",
    "# 6. 주요 변수들의 분포 비교 (로그 스케일 적용)\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('Key Variables Distribution Comparison (Log Scale)', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 로그 스케일이 적합한 변수들\n",
    "log_variables = ['DSPT_REQ_HR', 'arrival_time_diff', 'dispatch_time_diff']\n",
    "\n",
    "for i, var in enumerate(log_variables):\n",
    "    if var in df_processed.columns:\n",
    "        row = i // 2\n",
    "        col = i % 2\n",
    "        \n",
    "        # 양수 값만 필터링 (로그 변환을 위해)\n",
    "        positive_data = df_processed[df_processed[var] > 0][var]\n",
    "        \n",
    "        if len(positive_data) > 0:\n",
    "            # 로그 변환\n",
    "            log_data = np.log1p(positive_data)  # log1p는 log(1+x)로 0값도 처리 가능\n",
    "            \n",
    "            axes[row, col].hist(log_data, bins=30, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "            axes[row, col].set_title(f'{var} - Log Transformed Distribution', fontsize=12, fontweight='bold')\n",
    "            axes[row, col].set_xlabel('log(1 + value)')\n",
    "            axes[row, col].set_ylabel('Frequency')\n",
    "            axes[row, col].grid(True, alpha=0.3)\n",
    "            \n",
    "            # 통계 정보\n",
    "            mean_log = log_data.mean()\n",
    "            std_log = log_data.std()\n",
    "            axes[row, col].text(0.02, 0.98, \n",
    "                               f'Log Mean: {mean_log:.2f}\\nLog Std: {std_log:.2f}',\n",
    "                               transform=axes[row, col].transAxes, \n",
    "                               verticalalignment='top',\n",
    "                               bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "# 마지막 subplot에 타겟 변수 분포\n",
    "axes[1, 1].hist(df_processed['FIRE_SUPESN_HR'], bins=30, alpha=0.7, color='salmon', edgecolor='black')\n",
    "axes[1, 1].set_title('FIRE_SUPESN_HR - Target Variable Distribution', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Value')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n=== Analysis Complete ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d419b450",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "# 분석할 변수들\n",
    "variables_to_plot = [\n",
    "    \"FIRE_SUPESN_HR\",        # 타겟 변수\n",
    "    \"DSPT_REQ_HR\",          # 출동 요청 시간\n",
    "    \"FRSTN_GRNDS_DSTNC\",    # 산림지역 거리\n",
    "    \"CNTR_GRNDS_DSTNC\",     # 중심지역 거리\n",
    "    \"LFDAU_GRNDS_DSTNC\",    # 인접지역 거리\n",
    "    \"arrival_time_diff\",     # 도착 시간 차이\n",
    "    \"dispatch_time_diff\"     # 출동 시간 차이\n",
    "]\n",
    "\n",
    "print(\"=== 변수별 왜도(Skewness) 분석 ===\")\n",
    "print(\"왜도 > 1: 심한 우편향, 왜도 < -1: 심한 좌편향\")\n",
    "print(\"왜도 0.5~1: 약간의 우편향, 왜도 -1~-0.5: 약간의 좌편향\")\n",
    "print(\"왜도 -0.5~0.5: 대칭에 가까움\")\n",
    "print()\n",
    "\n",
    "skewness_data = []\n",
    "for var in variables_to_plot:\n",
    "    if var in df_processed.columns:\n",
    "        data = df_processed[var]\n",
    "        skewness = stats.skew(data)\n",
    "        skewness_data.append({\n",
    "            'Variable': var,\n",
    "            'Skewness': skewness,\n",
    "            'Need_Log': abs(skewness) > 1,\n",
    "            'Description': 'High skew' if abs(skewness) > 1 else 'Normal'\n",
    "        })\n",
    "        \n",
    "        print(f\"{var}:\")\n",
    "        print(f\"  왜도: {skewness:.3f}\")\n",
    "        print(f\"  로그변환 필요: {'예' if abs(skewness) > 1 else '아니오'}\")\n",
    "        print(f\"  최솟값: {data.min()}\")\n",
    "        print(f\"  최댓값: {data.max()}\")\n",
    "        print(f\"  평균: {data.mean():.2f}\")\n",
    "        print(f\"  중앙값: {data.median():.2f}\")\n",
    "        print()\n",
    "\n",
    "# 왜도 기준으로 정렬\n",
    "skewness_df = pd.DataFrame(skewness_data)\n",
    "skewness_df = skewness_df.sort_values('Skewness', key=abs, ascending=False)\n",
    "\n",
    "print(\"=== 로그변환 우선순위 ===\")\n",
    "print(skewness_df.to_string(index=False))\n",
    "\n",
    "# 로그변환이 필요한 변수들\n",
    "log_needed = skewness_df[skewness_df['Need_Log'] == True]['Variable'].tolist()\n",
    "print(f\"\\n로그변환이 필요한 변수들: {log_needed}\")\n",
    "\n",
    "# 로그변환 전후 비교 그래프\n",
    "if log_needed:\n",
    "    print(f\"\\n=== 로그변환 전후 분포 비교 ===\")\n",
    "    \n",
    "    n_vars = len(log_needed)\n",
    "    fig, axes = plt.subplots(n_vars, 2, figsize=(15, 5*n_vars))\n",
    "    \n",
    "    if n_vars == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for i, var in enumerate(log_needed):\n",
    "        data = df_processed[var]\n",
    "        \n",
    "        # 원본 데이터 히스토그램\n",
    "        axes[i, 0].hist(data, bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "        axes[i, 0].set_title(f'{var} - Original Distribution', fontsize=12, fontweight='bold')\n",
    "        axes[i, 0].set_xlabel('Value')\n",
    "        axes[i, 0].set_ylabel('Frequency')\n",
    "        axes[i, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 로그변환 후 히스토그램 (양수 값만)\n",
    "        positive_data = data[data > 0]\n",
    "        if len(positive_data) > 0:\n",
    "            log_data = np.log1p(positive_data)\n",
    "            axes[i, 1].hist(log_data, bins=30, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "            axes[i, 1].set_title(f'{var} - Log Transformed (log1p)', fontsize=12, fontweight='bold')\n",
    "            axes[i, 1].set_xlabel('log(1 + value)')\n",
    "            axes[i, 1].set_ylabel('Frequency')\n",
    "            axes[i, 1].grid(True, alpha=0.3)\n",
    "            \n",
    "            # 변환 전후 왜도 비교\n",
    "            original_skew = stats.skew(data)\n",
    "            log_skew = stats.skew(log_data)\n",
    "            \n",
    "            axes[i, 0].text(0.02, 0.98, f'Skewness: {original_skew:.3f}', \n",
    "                           transform=axes[i, 0].transAxes, verticalalignment='top',\n",
    "                           bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "            axes[i, 1].text(0.02, 0.98, f'Skewness: {log_skew:.3f}', \n",
    "                           transform=axes[i, 1].transAxes, verticalalignment='top',\n",
    "                           bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\n=== 로그변환 권장사항 ===\")\n",
    "print(\"1. 왜도가 1보다 크거나 -1보다 작은 변수는 로그변환 고려\")\n",
    "print(\"2. 0이나 음수 값이 있는 경우 log1p(x) = log(1+x) 사용\")\n",
    "print(\"3. 극단값이 많은 변수는 로그변환으로 분포를 정규화\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650ca78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로그변환이 필요한 변수들 (7개 모두)\n",
    "log_variables = [\n",
    "    \"FIRE_SUPESN_HR\",        # 타겟 변수\n",
    "    \"DSPT_REQ_HR\",          # 출동 요청 시간\n",
    "    \"FRSTN_GRNDS_DSTNC\",    # 산림지역 거리\n",
    "    \"CNTR_GRNDS_DSTNC\",     # 중심지역 거리\n",
    "    \"LFDAU_GRNDS_DSTNC\",    # 인접지역 거리\n",
    "    \"arrival_time_diff\",     # 도착 시간 차이\n",
    "    \"dispatch_time_diff\"     # 출동 시간 차이\n",
    "]\n",
    "\n",
    "print(\"=== 로그변환 진행 ===\")\n",
    "print(f\"로그변환할 변수들: {log_variables}\")\n",
    "\n",
    "# 로그변환용 데이터프레임 생성\n",
    "df_processed_log = df_processed.copy()\n",
    "\n",
    "# 각 변수별로 로그변환 진행\n",
    "for var in log_variables:\n",
    "    if var in df_processed_log.columns:\n",
    "        print(f\"\\n[{var}] 로그변환 중...\")\n",
    "        \n",
    "        # 변환 전 통계\n",
    "        original_data = df_processed_log[var]\n",
    "        print(f\"  변환 전 - 최솟값: {original_data.min():.2f}, 최댓값: {original_data.max():.2f}\")\n",
    "        print(f\"  변환 전 - 평균: {original_data.mean():.2f}, 표준편차: {original_data.std():.2f}\")\n",
    "        \n",
    "        # 0이나 음수 값이 있는지 확인\n",
    "        non_positive_count = (original_data <= 0).sum()\n",
    "        if non_positive_count > 0:\n",
    "            print(f\"  주의: 0 이하 값 {non_positive_count}개 발견\")\n",
    "            print(f\"  log1p(x) = log(1+x) 사용\")\n",
    "        \n",
    "        # 로그변환 (log1p 사용하여 0값도 처리)\n",
    "        log_transformed = np.log1p(original_data)\n",
    "        \n",
    "        # 새로운 컬럼명 생성\n",
    "        new_col_name = f\"{var}_log\"\n",
    "        df_processed_log[new_col_name] = log_transformed\n",
    "        \n",
    "        # 변환 후 통계\n",
    "        print(f\"  변환 후 - 최솟값: {log_transformed.min():.2f}, 최댓값: {log_transformed.max():.2f}\")\n",
    "        print(f\"  변환 후 - 평균: {log_transformed.mean():.2f}, 표준편차: {log_transformed.std():.2f}\")\n",
    "        \n",
    "        # 왜도 비교\n",
    "        from scipy import stats\n",
    "        original_skew = stats.skew(original_data)\n",
    "        log_skew = stats.skew(log_transformed)\n",
    "        print(f\"  왜도 - 변환 전: {original_skew:.3f}, 변환 후: {log_skew:.3f}\")\n",
    "        \n",
    "        print(f\"  새 컬럼 생성: {new_col_name}\")\n",
    "    else:\n",
    "        print(f\"\\n[{var}] 컬럼이 존재하지 않습니다.\")\n",
    "\n",
    "print(f\"\\n=== 로그변환 완료 ===\")\n",
    "print(f\"원본 데이터 크기: {df_processed.shape}\")\n",
    "print(f\"로그변환 후 데이터 크기: {df_processed_log.shape}\")\n",
    "\n",
    "# 새로 생성된 컬럼들 확인\n",
    "new_log_columns = [col for col in df_processed_log.columns if col.endswith('_log')]\n",
    "print(f\"새로 생성된 로그변환 컬럼들: {new_log_columns}\")\n",
    "\n",
    "# 로그변환 전후 분포 비교 그래프 (에러 처리 포함)\n",
    "fig, axes = plt.subplots(len(log_variables), 2, figsize=(15, 5*len(log_variables)))\n",
    "\n",
    "if len(log_variables) == 1:\n",
    "    axes = axes.reshape(1, -1)\n",
    "\n",
    "for i, var in enumerate(log_variables):\n",
    "    if var in df_processed_log.columns:\n",
    "        # 원본 데이터 히스토그램\n",
    "        try:\n",
    "            axes[i, 0].hist(df_processed_log[var], bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "            axes[i, 0].set_title(f'{var} - Original Distribution', fontsize=12, fontweight='bold')\n",
    "            axes[i, 0].set_xlabel('Value')\n",
    "            axes[i, 0].set_ylabel('Frequency')\n",
    "            axes[i, 0].grid(True, alpha=0.3)\n",
    "        except Exception as e:\n",
    "            axes[i, 0].text(0.5, 0.5, f'Error plotting {var}\\n{str(e)}', \n",
    "                           ha='center', va='center', transform=axes[i, 0].transAxes)\n",
    "            axes[i, 0].set_title(f'{var} - Plotting Error', fontsize=12, fontweight='bold')\n",
    "        \n",
    "        # 로그변환 후 히스토그램\n",
    "        log_col = f\"{var}_log\"\n",
    "        try:\n",
    "            # 무한대 값이나 NaN 값 제거\n",
    "            log_data = df_processed_log[log_col].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "            \n",
    "            if len(log_data) > 0:\n",
    "                axes[i, 1].hist(log_data, bins=30, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "                axes[i, 1].set_title(f'{var} - Log Transformed (log1p)', fontsize=12, fontweight='bold')\n",
    "                axes[i, 1].set_xlabel('log(1 + value)')\n",
    "                axes[i, 1].set_ylabel('Frequency')\n",
    "                axes[i, 1].grid(True, alpha=0.3)\n",
    "                \n",
    "                # 통계 정보 표시\n",
    "                original_skew = stats.skew(df_processed_log[var])\n",
    "                log_skew = stats.skew(log_data)\n",
    "                \n",
    "                axes[i, 0].text(0.02, 0.98, f'Skewness: {original_skew:.3f}', \n",
    "                                transform=axes[i, 0].transAxes, verticalalignment='top',\n",
    "                                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "                axes[i, 1].text(0.02, 0.98, f'Skewness: {log_skew:.3f}', \n",
    "                                transform=axes[i, 1].transAxes, verticalalignment='top',\n",
    "                                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "            else:\n",
    "                axes[i, 1].text(0.5, 0.5, f'No valid data for {log_col}', \n",
    "                               ha='center', va='center', transform=axes[i, 1].transAxes)\n",
    "                axes[i, 1].set_title(f'{var} - No Valid Data', fontsize=12, fontweight='bold')\n",
    "                \n",
    "        except Exception as e:\n",
    "            axes[i, 1].text(0.5, 0.5, f'Error plotting {log_col}\\n{str(e)}', \n",
    "                           ha='center', va='center', transform=axes[i, 1].transAxes)\n",
    "            axes[i, 1].set_title(f'{var} - Plotting Error', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 최종 데이터프레임 정보\n",
    "print(\"\\n=== 최종 데이터프레임 정보 ===\")\n",
    "print(f\"데이터 크기: {df_processed_log.shape}\")\n",
    "print(f\"컬럼 수: {len(df_processed_log.columns)}\")\n",
    "print(f\"데이터 타입:\")\n",
    "print(df_processed_log.dtypes.value_counts())\n",
    "\n",
    "# 로그변환된 컬럼들의 기본 통계 (에러 처리 포함)\n",
    "print(f\"\\n=== 로그변환된 컬럼들의 기본 통계 ===\")\n",
    "try:\n",
    "    # 무한대 값과 NaN 값 처리\n",
    "    log_columns_clean = df_processed_log[new_log_columns].replace([np.inf, -np.inf], np.nan)\n",
    "    log_columns_stats = log_columns_clean.describe()\n",
    "    print(log_columns_stats)\n",
    "except Exception as e:\n",
    "    print(f\"통계 계산 중 오류: {str(e)}\")\n",
    "    \n",
    "    # 개별 컬럼별로 확인\n",
    "    for col in new_log_columns:\n",
    "        try:\n",
    "            clean_data = df_processed_log[col].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "            print(f\"\\n{col}:\")\n",
    "            print(f\"  유효한 데이터 수: {len(clean_data)}\")\n",
    "            print(f\"  최솟값: {clean_data.min():.4f}\")\n",
    "            print(f\"  최댓값: {clean_data.max():.4f}\")\n",
    "            print(f\"  평균: {clean_data.mean():.4f}\")\n",
    "        except Exception as e2:\n",
    "            print(f\"\\n{col}: 오류 발생 - {str(e2)}\")\n",
    "\n",
    "print(f\"\\n로그변환이 완료되었습니다!\")\n",
    "print(f\"새로운 객체: df_processed_log\")\n",
    "print(f\"새로 추가된 컬럼: {new_log_columns}\")\n",
    "\n",
    "# 무한대 값과 NaN 값 확인\n",
    "print(f\"\\n=== 데이터 품질 확인 ===\")\n",
    "for col in new_log_columns:\n",
    "    inf_count = np.isinf(df_processed_log[col]).sum()\n",
    "    nan_count = df_processed_log[col].isna().sum()\n",
    "    print(f\"{col}: 무한대 {inf_count}개, NaN {nan_count}개\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8734b705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIRE_SUPESN_HR 제거 (타겟 변수)\n",
    "df_processed_log = df_processed_log.drop(columns=['FIRE_SUPESN_HR'])\n",
    "\n",
    "print(f\"FIRE_SUPESN_HR 제거 완료\")\n",
    "print(f\"현재 데이터 크기: {df_processed_log.shape}\")\n",
    "print(f\"제거된 컬럼: FIRE_SUPESN_HR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddd2f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로그변환된 데이터를 CSV로 저장\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# 파일명 생성\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_filename = f\"preprocessed_wildfire_log_{timestamp}.csv\"\n",
    "\n",
    "# CSV 저장\n",
    "df_processed_log.to_csv(output_filename, index=False, encoding='utf-8-sig')\n",
    "\n",
    "# 저장 확인\n",
    "if os.path.exists(output_filename):\n",
    "    file_size = os.path.getsize(output_filename) / (1024 * 1024)\n",
    "    print(f\"CSV 저장 완료: {output_filename}\")\n",
    "    print(f\"파일 크기: {file_size:.2f} MB\")\n",
    "    print(f\"데이터 크기: {df_processed_log.shape}\")\n",
    "else:\n",
    "    print(\"CSV 저장 실패\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a7fbdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
