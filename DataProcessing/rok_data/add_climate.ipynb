{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e93afb6-ad4a-457c-b3a6-3597bf3fd6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[완료] 대체+플래그 결과 저장: /Users/igangsan/Desktop/forest_geo_climate_added.csv\n",
      " - any_imputed=True 행 수: 251\n",
      " - impute_radius 분포:\n",
      "impute_radius\n",
      "0    3309\n",
      "1     235\n",
      "2      16\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "CSV(일 단위 날짜) ← NetCDF(시간 단위) 기상자료 결합\n",
    "+ 결측값을 '가장 가까운 위/경도 격자'로 대체(Imputation) + flag\n",
    "\n",
    "- CSV: wildfire_2019_2023_combine.csv\n",
    "  - 날짜: RCPT_DT (예: 2019.1.20 / 2019.01.20 모두 허용)\n",
    "  - 위치: latitude, longitude\n",
    "- NC 폴더: /Users/igangsan/Desktop/climate (확장자 없이 저장된 NetCDF도 자동 감지)\n",
    "- 출력: wildfire_with_daily_climate_imputed.csv\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "# ================== 경로/칼럼 설정 ==================\n",
    "CSV_PATH = \"/Users/igangsan/Desktop/forest_geo_added.csv\"\n",
    "\n",
    "CLIMATE_DIR   = \"/Users/igangsan/Desktop/climate\"\n",
    "\n",
    "\n",
    "OUT_PATH = \"/Users/igangsan/Desktop/forest_geo_climate_added.csv\"\n",
    "\n",
    "DATE_COL = \"rcpt_dt\"\n",
    "LAT_COL  = \"latitude\"\n",
    "LON_COL  = \"longitude\"\n",
    "\n",
    "# 사용할 변수(있으면 사용)\n",
    "VARS_WANT = [\"t2m\",\"d2m\",\"u10\",\"v10\",\"tp\",\"ssrd\",\"pev\"]\n",
    "# 일 단위 결과 칼럼 이름(변환/집계 정의)\n",
    "OUT_COLS = [\n",
    "    \"t2m_mean_C\",\"t2m_min_C\",\"t2m_max_C\",\n",
    "    \"d2m_mean_C\",\"d2m_min_C\",\"d2m_max_C\",\n",
    "    \"u10_mean_ms\",\"v10_mean_ms\",\"wind_speed_mean\",\"wind_dir_deg\",\n",
    "    \"tp_sum_mm\",\"pev_sum_mm\",\n",
    "    \"ssrd_sum_Jm2\",\"ssrd_sum_MJm2\",\n",
    "]\n",
    "# ====================================================\n",
    "\n",
    "# ---------- 유틸 함수들 ----------\n",
    "def k_to_c(x): return x - 273.15\n",
    "def wind_speed(u, v): return np.sqrt(u**2 + v**2)\n",
    "def wind_dir_from_uv(u, v):  # 0=북, 90=동 (바람 '불어오는' 방향)\n",
    "    return (np.degrees(np.arctan2(-u, -v)) + 360.0) % 360.0\n",
    "\n",
    "# 기존 to_date_series_flex() 완전히 교체\n",
    "def to_date_series_flex(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    문자열에서 '연-월-일'의 처음 3개 숫자 블록만 사용해 date로 변환.\n",
    "    허용 예: \n",
    "      - 2019-01-20 04:23:23\n",
    "      - 2019.1.20\n",
    "      - 2019/01/20 4:10:00 PM\n",
    "      - 20190120, 20190120042323, 201901200423\n",
    "    \"\"\"\n",
    "    s = s.astype(str).str.strip()\n",
    "\n",
    "    def parse_one(x: str):\n",
    "        x = x.strip()\n",
    "        if not x:\n",
    "            return pd.NaT\n",
    "        # 1) 순수 숫자: YYYYMMDD[HHMM[SS]]\n",
    "        if x.isdigit():\n",
    "            if len(x) >= 14:\n",
    "                return pd.to_datetime(x[:14], format=\"%Y%m%d%H%M%S\", errors=\"coerce\")\n",
    "            if len(x) == 12:\n",
    "                return pd.to_datetime(x, format=\"%Y%m%d%H%M\", errors=\"coerce\")\n",
    "            if len(x) == 8:\n",
    "                return pd.to_datetime(x, format=\"%Y%m%d\", errors=\"coerce\")\n",
    "        # 2) 그 외: 처음 3개의 숫자 토큰만 추출(연,월,일)\n",
    "        toks = re.findall(r\"\\d+\", x)\n",
    "        if len(toks) >= 3:\n",
    "            y, m, d = toks[0], toks[1], toks[2]\n",
    "            ts = pd.to_datetime(f\"{y}-{m}-{d}\", errors=\"coerce\")\n",
    "            if ts is not None:\n",
    "                return ts\n",
    "        # 3) 일반 파서 (T/점/슬래시/공백 섞여도)\n",
    "        x2 = x.replace(\"T\", \" \")\n",
    "        ts = pd.to_datetime(x2, errors=\"coerce\", infer_datetime_format=True)\n",
    "        if pd.isna(ts):\n",
    "            ts = pd.to_datetime(x2.replace(\".\", \"-\").replace(\"/\", \"-\"),\n",
    "                                errors=\"coerce\", infer_datetime_format=True)\n",
    "        return ts\n",
    "\n",
    "    ts = s.apply(parse_one)\n",
    "    return ts.dt.date\n",
    "\n",
    "def looks_like_netcdf(path: str) -> bool:\n",
    "    try:\n",
    "        with open(path, \"rb\") as f:\n",
    "            head = f.read(8)\n",
    "        if head.startswith(b\"CDF\"):              # NetCDF classic/64-bit\n",
    "            return True\n",
    "        if head == b\"\\x89HDF\\r\\n\\x1a\\n\":         # NetCDF4(HDF5)\n",
    "            return True\n",
    "    except Exception:\n",
    "        pass\n",
    "    if path.lower().endswith(\".nc\"):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def open_dataset_any(path: str):\n",
    "    for eng in [\"h5netcdf\",\"scipy\",\"netcdf4\"]:\n",
    "        try:\n",
    "            return xr.open_dataset(path, engine=eng)\n",
    "        except Exception:\n",
    "            pass\n",
    "    try:\n",
    "        return xr.open_dataset(path, engine=\"cfgrib\")   # (설치되어 있으면)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "def list_nc_files(dir_path: str):\n",
    "    out = []\n",
    "    for name in os.listdir(dir_path):\n",
    "        p = os.path.join(dir_path, name)\n",
    "        if os.path.isfile(p) and not name.startswith(\".\") and looks_like_netcdf(p):\n",
    "            out.append(p)\n",
    "    return sorted(out)\n",
    "\n",
    "def nearest_index(arr_1d: np.ndarray, value: float) -> int:\n",
    "    return int(np.nanargmin(np.abs(arr_1d - value)))\n",
    "\n",
    "# ---------- CSV 로드 ----------\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "missing = {DATE_COL, LAT_COL, LON_COL} - set(df.columns)\n",
    "if missing:\n",
    "    raise ValueError(f\"CSV에 필요한 칼럼이 없습니다: {missing}\")\n",
    "\n",
    "df[\"_date\"] = to_date_series_flex(df[DATE_COL])\n",
    "if df[\"_date\"].isna().any():\n",
    "    examples = df.loc[df[\"_date\"].isna(), DATE_COL].unique()[:5]\n",
    "    raise ValueError(f\"날짜 파싱 실패 예시(최대 5개): {examples}\")\n",
    "\n",
    "# ---------- NetCDF 열기 & 일 집계 ----------\n",
    "nc_files = list_nc_files(CLIMATE_DIR)\n",
    "if not nc_files:\n",
    "    raise FileNotFoundError(f\"NetCDF 후보 파일을 찾지 못했습니다: {CLIMATE_DIR}\")\n",
    "\n",
    "datasets = []\n",
    "for fp in nc_files:\n",
    "    ds1 = open_dataset_any(fp)\n",
    "    if ds1 is not None:\n",
    "        datasets.append(ds1)\n",
    "if not datasets:\n",
    "    raise RuntimeError(\"NetCDF 파일을 열 수 없습니다.\")\n",
    "\n",
    "ds = xr.combine_by_coords(datasets, combine_attrs=\"override\")\n",
    "\n",
    "time_name = \"valid_time\" if \"valid_time\" in ds.coords else (\"time\" if \"time\" in ds.coords else None)\n",
    "if time_name is None:\n",
    "    raise KeyError(\"Dataset에 시간 좌표(valid_time/time)가 없습니다.\")\n",
    "\n",
    "vars_present = [v for v in VARS_WANT if v in ds.data_vars]\n",
    "if not vars_present:\n",
    "    raise KeyError(f\"필요 변수({VARS_WANT})가 없습니다. 실제 변수: {list(ds.data_vars)}\")\n",
    "\n",
    "agg = {}\n",
    "\n",
    "if \"t2m\" in vars_present:\n",
    "    agg[\"t2m_mean_C\"] = k_to_c(ds[\"t2m\"]).resample({time_name:\"1D\"}).mean()\n",
    "    agg[\"t2m_min_C\"]  = k_to_c(ds[\"t2m\"]).resample({time_name:\"1D\"}).min()\n",
    "    agg[\"t2m_max_C\"]  = k_to_c(ds[\"t2m\"]).resample({time_name:\"1D\"}).max()\n",
    "\n",
    "if \"d2m\" in vars_present:\n",
    "    agg[\"d2m_mean_C\"] = k_to_c(ds[\"d2m\"]).resample({time_name:\"1D\"}).mean()\n",
    "    agg[\"d2m_min_C\"]  = k_to_c(ds[\"d2m\"]).resample({time_name:\"1D\"}).min()\n",
    "    agg[\"d2m_max_C\"]  = k_to_c(ds[\"d2m\"]).resample({time_name:\"1D\"}).max()\n",
    "\n",
    "if \"u10\" in vars_present and \"v10\" in vars_present:\n",
    "    u_daily = ds[\"u10\"].resample({time_name:\"1D\"}).mean()\n",
    "    v_daily = ds[\"v10\"].resample({time_name:\"1D\"}).mean()\n",
    "    agg[\"u10_mean_ms\"]     = u_daily\n",
    "    agg[\"v10_mean_ms\"]     = v_daily\n",
    "    agg[\"wind_speed_mean\"] = wind_speed(u_daily, v_daily)\n",
    "    agg[\"wind_dir_deg\"]    = xr.apply_ufunc(\n",
    "        wind_dir_from_uv, u_daily, v_daily,\n",
    "        vectorize=True, dask=\"parallelized\", output_dtypes=[float]\n",
    "    )\n",
    "\n",
    "if \"tp\" in vars_present:\n",
    "    agg[\"tp_sum_mm\"]  = ds[\"tp\"].resample({time_name:\"1D\"}).sum() * 1000.0\n",
    "if \"pev\" in vars_present:\n",
    "    agg[\"pev_sum_mm\"] = ds[\"pev\"].resample({time_name:\"1D\"}).sum() * 1000.0\n",
    "if \"ssrd\" in vars_present:\n",
    "    ssrd_daily = ds[\"ssrd\"].resample({time_name:\"1D\"}).sum()\n",
    "    agg[\"ssrd_sum_Jm2\"]  = ssrd_daily\n",
    "    agg[\"ssrd_sum_MJm2\"] = ssrd_daily / 1e6\n",
    "\n",
    "if not agg:\n",
    "    raise RuntimeError(\"집계할 변수가 없습니다.\")\n",
    "\n",
    "daily = xr.Dataset(agg)\n",
    "\n",
    "# 날짜 좌표를 단순 date로 바꿔 정합 ↑\n",
    "daily_dates = pd.to_datetime(daily[time_name].values).date\n",
    "daily = daily.assign_coords({time_name: daily_dates})\n",
    "\n",
    "# ---------- 최근접 격자 결합 (1차) ----------\n",
    "lat_vals = daily.latitude.values\n",
    "lon_vals = daily.longitude.values\n",
    "dates_avail = set(daily[time_name].values.tolist())  # python date 객체 집합\n",
    "\n",
    "def pick_point(lat, lon, date_obj):\n",
    "    \"\"\"최근접 격자 1개에서 값 추출 (date가 없으면 NaN 반환)\"\"\"\n",
    "    if (pd.isna(lat) or pd.isna(lon) or pd.isna(date_obj) or (date_obj not in dates_avail)):\n",
    "        return {k: np.nan for k in daily.data_vars}\n",
    "    try:\n",
    "        ilat = nearest_index(lat_vals, float(lat))\n",
    "        ilon = nearest_index(lon_vals, float(lon))\n",
    "        p = daily.sel({time_name: date_obj}).isel(latitude=ilat, longitude=ilon)\n",
    "        return {k: float(p[k].values) for k in daily.data_vars}\n",
    "    except Exception:\n",
    "        return {k: np.nan for k in daily.data_vars}\n",
    "\n",
    "# 1차 값 붙이기\n",
    "rows = df[[LAT_COL, LON_COL, \"_date\"]].to_dict(orient=\"records\")\n",
    "first_values = [pick_point(r[LAT_COL], r[LON_COL], r[\"_date\"]) for r in rows]\n",
    "met_df = pd.DataFrame(first_values)\n",
    "\n",
    "# ---------- 결측 대체(가장 가까운 격자) ----------\n",
    "# 주변 이웃 탐색 반경 설정(격자 인덱스 기준): 1~3칸까지 확대 탐색\n",
    "MAX_RADIUS = 3\n",
    "var_list = list(daily.data_vars)\n",
    "\n",
    "# per-variable imputation flag 컬럼 준비\n",
    "for v in var_list:\n",
    "    met_df[f\"{v}_imputed\"] = False\n",
    "# 행 전체에 대한 flag/반경 기록\n",
    "met_df[\"any_imputed\"] = False\n",
    "met_df[\"impute_radius\"] = 0  # 0=원래 최근접으로 채워짐(대체 없음)\n",
    "\n",
    "# 빠르게 접근하기 위해 daily를 날짜별로 나눠두기\n",
    "daily_by_date = {d: daily.sel({time_name: d}) for d in dates_avail}\n",
    "\n",
    "def fill_from_neighbors(lat, lon, date_obj, current_row):\n",
    "    \"\"\"현재 행의 각 변수에 대해 NaN이면 반경을 늘리며 이웃 격자에서 첫 유효값으로 대체\"\"\"\n",
    "    if (pd.isna(lat) or pd.isna(lon) or pd.isna(date_obj) or (date_obj not in daily_by_date)):\n",
    "        return current_row, 0  # 대체 불가\n",
    "    \n",
    "    plane = daily_by_date[date_obj]  # (latitude, longitude) 2D 필드들\n",
    "    nlat = plane.sizes[\"latitude\"]\n",
    "    nlon = plane.sizes[\"longitude\"]\n",
    "\n",
    "    # 기준 인덱스\n",
    "    try:\n",
    "        i0 = nearest_index(lat_vals, float(lat))\n",
    "        j0 = nearest_index(lon_vals, float(lon))\n",
    "    except Exception:\n",
    "        return current_row, 0\n",
    "\n",
    "    used_radius = 0\n",
    "    # 변수별로 결측이면 이웃 탐색\n",
    "    for v in var_list:\n",
    "        if np.isnan(current_row[v]):\n",
    "            found = False\n",
    "            # 반경 1..MAX_RADIUS 탐색\n",
    "            for r in range(1, MAX_RADIUS+1):\n",
    "                # r-정사각형 테두리 이웃 스캔(바깥 테두리만)\n",
    "                candidates = []\n",
    "                for di in range(-r, r+1):\n",
    "                    for dj in [-r, r]:\n",
    "                        candidates.append((i0+di, j0+dj))\n",
    "                for dj in range(-r+1, r):\n",
    "                    for di in [-r, r]:\n",
    "                        candidates.append((i0+di, j0+dj))\n",
    "                # 후보 중 유효값 찾기\n",
    "                for (ii, jj) in candidates:\n",
    "                    if 0 <= ii < nlat and 0 <= jj < nlon:\n",
    "                        val = float(plane[v].isel(latitude=ii, longitude=jj).values)\n",
    "                        if not np.isnan(val):\n",
    "                            current_row[v] = val\n",
    "                            current_row[f\"{v}_imputed\"] = True\n",
    "                            used_radius = max(used_radius, r)\n",
    "                            found = True\n",
    "                            break\n",
    "                if found:\n",
    "                    break\n",
    "    return current_row, used_radius\n",
    "\n",
    "# 결측이 있는 행들에 대해 이웃 격자 대체 수행\n",
    "mask_missing_any = met_df[var_list].isna().any(axis=1)\n",
    "for idx in met_df.index[mask_missing_any]:\n",
    "    lat = df.at[idx, LAT_COL]\n",
    "    lon = df.at[idx, LON_COL]\n",
    "    date_obj = df.at[idx, \"_date\"]\n",
    "    row_vals = met_df.loc[idx, var_list + [f\"{v}_imputed\" for v in var_list] + [\"any_imputed\",\"impute_radius\"]].to_dict()\n",
    "    # dict에서 필요한 키만 활용\n",
    "    row_core = {k: row_vals[k] for k in var_list}\n",
    "    row_core, radius_used = fill_from_neighbors(lat, lon, date_obj, row_core)\n",
    "    # 결과 반영\n",
    "    for v in var_list:\n",
    "        met_df.at[idx, v] = row_core[v]\n",
    "    if radius_used > 0:\n",
    "        met_df.at[idx, \"any_imputed\"] = True\n",
    "        met_df.at[idx, \"impute_radius\"] = radius_used\n",
    "        for v in var_list:\n",
    "            # 위에서 True로 바꿨을 수 있으니 그대로 둠; False면 유지\n",
    "            pass\n",
    "\n",
    "# ---------- 원본 단위 → 사람이 쓰기 좋은 칼럼으로 rename ----------\n",
    "# daily.data_vars 기준으로 met_df는 원래 변수명(t2m, tp, ...)가 아니라\n",
    "# 이미 우리가 만들어둔 일 집계 칼럼(agg) 이름들로 들어와 있음.\n",
    "# (위 pick_point/plane가 daily(agg)에서 읽으므로 met_df 컬럼은 agg 키들 = OUT_COLS)\n",
    "# 다만 엔진/환경에 따라 일부만 존재할 수 있으니 존재하는 것만 유지.\n",
    "\n",
    "keep_cols = [c for c in OUT_COLS if c in met_df.columns]  # 안전하게\n",
    "\n",
    "# ---------- 최종 병합 & 저장 ----------\n",
    "# (원본 df에서 _date 제거 + 기상데이터 + imputation flag)\n",
    "\n",
    "out = pd.concat(\n",
    "    [df.drop(columns=[\"_date\"]), met_df[keep_cols + [\"any_imputed\", \"impute_radius\"]]],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "out.to_csv(OUT_PATH, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"[완료] 대체+플래그 결과 저장: {OUT_PATH}\")\n",
    "\n",
    "# 간단 요약\n",
    "n_any_imp = int(out[\"any_imputed\"].sum())\n",
    "print(f\" - any_imputed=True 행 수: {n_any_imp}\")\n",
    "print(\" - impute_radius 분포:\")\n",
    "print(out[\"impute_radius\"].value_counts(dropna=False).sort_index())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864fa7e3-4cc6-45b9-b073-722ae18b5a28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
